{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "base_lm.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/durham-abric/Comp551_Final_Proj/blob/master/base_lm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Wx1XADhOCTKL",
        "colab_type": "code",
        "outputId": "1b5ebf00-905a-4d4c-dbb4-e971067414f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-xtNpmqICWoj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import concat\n",
        "from tensorflow.layers import Conv1D\n",
        "from tensorflow.layers import Dense\n",
        "from tensorflow.layers import Dropout\n",
        "from tensorflow.layers import Flatten\n",
        "from tensorflow.contrib import rnn\n",
        "from tensorflow.contrib.rnn import InputProjectionWrapper\n",
        "from tensorflow.nn import relu\n",
        "from tensorflow.nn import softmax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mcUQGjragAD2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def weights_init(shape):\n",
        "    return tf.Variable(tf.truncated_normal(shape=shape, stddev=0.05))\n",
        "  \n",
        "def bias_init(shape):\n",
        "    return tf.Variable(tf.zeros(shape=shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m5_K7Y0Dwq4G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def embedding_layer(vocab_size, embeding_size, inputs):\n",
        "  \n",
        "    word_embedings = tf.Variable(tf.random_uniform([vocab_size, embeding_size]))\n",
        "    embed = tf.nn.embedding_lookup(word_embedings, inputs)\n",
        "#     embed_expended = tf.expand_dims(embed, -1) #expend dims to 4d for conv layer\n",
        "    return embed_expended"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0gWu1TaU-bfD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def define_inputs(batch_size, sequence_len):\n",
        "  \n",
        "    inputs = tf.placeholder(tf.int32, [batch_size, sequence_len], name='inputs')\n",
        "    targets = tf.placeholder(tf.float32, [batch_size, 1], name='target')\n",
        "    keep_probs = tf.placeholder(tf.float32, name='keep_probs')\n",
        "    \n",
        "    return inputs, targets, keep_probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TtxM4TIznhX6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv_1d(input, kernel_size, number_of_filters, strides=(1, 1), activation=tf.nn.relu, max_pool=True):\n",
        "    weights = weights_init([kernel_size, kernel_size, 1, number_of_filters])\n",
        "    bias = bias_init([number_of_filters])\n",
        "  \n",
        "    layer = tf.nn.conv2d(input, filter=weights, strides=[1, strides[0], strides[1], 1], padding='SAME')\n",
        "    \n",
        "    if activation != None:\n",
        "        layer = activation(layer)\n",
        "    \n",
        "    if max_pool:\n",
        "        layer = tf.nn.max_pool(layer, ksize=[1, 2, 2 ,1], strides=[1, 2, 2, 1], padding='SAME')\n",
        "    \n",
        "    return layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1MxwRHb8NiJM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def dense(input, in_size, out_size, dropout=0.25, activation=tf.nn.relu):\n",
        "    weights = weights_init([in_size, out_size])\n",
        "    bias = bias_init([out_size])\n",
        "    \n",
        "    layer = tf.matmul(input, weights) + bias\n",
        "    \n",
        "    if activation != None:\n",
        "        layer = activation(layer)\n",
        "    \n",
        "    if dropout:\n",
        "        layer = tf.nn.dropout(layer, dropout)\n",
        "        \n",
        "    return layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GUKg0ZM0WD00",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def lstm_layer(lstm_size, number_of_layers, batch_size = 128, dropout_rate = 0.0):\n",
        "  \n",
        "    def cell(size, dropout_rate=None):\n",
        "        layer = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
        "        \n",
        "        return tf.contrib.rnn.DropoutWrapper(layer, output_keep_prob=dropout_rate)\n",
        "            \n",
        "    cell = tf.contrib.rnn.MultiRNNCell([cell(lstm_size, dropout_rate) for _ in range(number_of_layers)])\n",
        "    \n",
        "    init_state = cell.zero_state(batch_size, tf.float32)\n",
        "    return cell, init_state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ft-YBAxVLuI1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def flatten_cnn(layers, shape):\n",
        "  conv_layer_reshaped = []\n",
        "    \n",
        "  for l in layers:\n",
        "    new_l = tf.reshape(l, [shape, -1])\n",
        "    conv_layer_reshaped.append(new_l) \n",
        "    \n",
        "  return conv_layer_reshaped"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "92FIXlfPWXNf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class LanguageModel(object):\n",
        "  \n",
        "  def __init__(self, learning_rate=0.02, dropout_rate=0.25, batch_size=128, project_dim = 1024, seq_len=50, vocab_size=1024, embed_size=300,\n",
        "               number_of_lstm_layers=2, lstm_units=8192):\n",
        "    \n",
        "    tf.reset_default_graph()\n",
        "    self.inputs, self.targets, self.keep_probs = define_inputs(batch_size, seq_len)\n",
        "\n",
        "    word_embeddings = tf.get_variable('word_embeddings', [vocab_size, embed_size])\n",
        "    embedded_word_ids = tf.nn.embedding_lookup(word_embeddings, self.inputs)\n",
        "\n",
        "    \n",
        "    # Neural network\n",
        "    # 8 conv-1d in parallel concatenated\n",
        "    conv_block_1 = tf.layers.conv1d(embedded_word_ids, 32, 1)\n",
        "    conv_block_2 = tf.layers.conv1d(embedded_word_ids, 32, 2)\n",
        "    conv_block_3 = tf.layers.conv1d(embedded_word_ids, 64, 3)\n",
        "    conv_block_4 = tf.layers.conv1d(embedded_word_ids, 128, 4)\n",
        "    conv_block_5 = tf.layers.conv1d(embedded_word_ids, 256, 5)\n",
        "    conv_block_6 = tf.layers.conv1d(embedded_word_ids, 512, 6)\n",
        "    conv_block_7 = tf.layers.conv1d(embedded_word_ids, 1028, 7)\n",
        "    conv_block_8 = tf.layers.conv1d(embedded_word_ids, 2048, 7)\n",
        "    \n",
        "    conv_layer = [conv_block_1, conv_block_2, conv_block_3,\n",
        "                  conv_block_4, conv_block_5, conv_block_6,\n",
        "                  conv_block_7, conv_block_8]\n",
        "    \n",
        "    conv_layer = flatten_cnn(conv_layer, batch_size)\n",
        "      \n",
        "      \n",
        "    concatenated_conv = tf.concat(conv_layer, 1)\n",
        "        \n",
        "    # Feed Forward Layers\n",
        "    logits = tf.layers.dense(concatenated_conv, 4096)\n",
        "    logits = tf.layers.dense(logits, 4096)\n",
        "    \n",
        "#     # Projection\n",
        "#     ## TODO\n",
        "    \n",
        "#     # LSTM Layers\n",
        "    lstm_cell, init_state = lstm_layer(lstm_units, number_of_lstm_layers, batch_size)\n",
        "    logits, states = tf.nn.dynamic_rnn(lstm_cell, logits, initial_state=init_state)\n",
        "\n",
        "    \n",
        "#     # Predictions softmax\n",
        "    logits = tf.layers.dense(logits, 800000)\n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GiIfOKaZO29I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = LanguageModel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m5jEHprXO7rh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}